{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GFHIFjocKq1"
   },
   "source": [
    "# Breast Cancer Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49546,
     "status": "ok",
     "timestamp": 1740498982366,
     "user": {
      "displayName": "valentina bernal",
      "userId": "15816178007629812225"
     },
     "user_tz": 0
    },
    "id": "cKVc3F1169w3",
    "outputId": "c5ccf820-de74-42f7-f188-deae34e9149b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# make connection to google drive to access data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTSdMq2kbnnc"
   },
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHzNVV_OcGSZ"
   },
   "source": [
    "## Accessing Data Files in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwVI-wY7VGQl"
   },
   "outputs": [],
   "source": [
    "# # set up directory paths to image files\n",
    "# train_path = \"/content/drive/My Drive/Deep Learning and Generative AI/C-NMC_Leukemia/training_data/fold_0\"\n",
    "# test_path = \"/content/drive/My Drive/Deep Learning and Generative AI/C-NMC_Leukemia/testing_data/C-NMC_test_final_phase_data\"\n",
    "# val_path = \"/content/drive/My Drive/Deep Learning and Generative AI/C-NMC_Leukemia/validation_data/val_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXQad3VlbdQg"
   },
   "outputs": [],
   "source": [
    "combined_path_train = \"/content/drive/My Drive/Deep Learning and Generative AI/breast_cancer/Dataset_BUSI_with_GT/combined_images_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "error",
     "timestamp": 1740499026385,
     "user": {
      "displayName": "valentina bernal",
      "userId": "15816178007629812225"
     },
     "user_tz": 0
    },
    "id": "FkSiF55Cbb5j",
    "outputId": "8a6b6838-68d4-4259-d191-12b26b73c444"
   },
   "outputs": [],
   "source": [
    "normal_imgs = [] # store normal cell image names\n",
    "cancer_imgs = [] # store cancer cell image names\n",
    "\n",
    "for file in os.listdir(combined_path_train+\"/normal\"): # normal cells\n",
    "  if 'mask' not in file:\n",
    "    normal_imgs.append(file)\n",
    "for file in os.listdir(combined_path_train+\"/malignant\"): # cancer cells\n",
    "  if 'mask' not in file:\n",
    "    cancer_imgs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7dybQyD30vY"
   },
   "outputs": [],
   "source": [
    "len(normal_imgs), len(cancer_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gANO4Rk_cuzY"
   },
   "outputs": [],
   "source": [
    "image_path = os.path.join(combined_path_train+\"/normal\",normal_imgs[2]) # create the full path to the image\n",
    "img = mpimg.imread(image_path) # read the image data\n",
    "print(img.shape) # print the shape of the image data\n",
    "plt.imshow(img) # display the image data\n",
    "plt.title(\"Normal Image\", fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VKIK4hVcuwd"
   },
   "outputs": [],
   "source": [
    "image_path = os.path.join(combined_path_train+\"/malignant\", cancer_imgs[2]) # create the full path to the image\n",
    "img = mpimg.imread(image_path) # read the image data\n",
    "print(img.shape) # print the shape of the image data\n",
    "plt.imshow(img) # display the image data\n",
    "plt.title(\"Cancer Image\", fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYOs4qeT3muz"
   },
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d51WRbD181po"
   },
   "outputs": [],
   "source": [
    "dim1 = [] # storing first dimensions of image for analysis\n",
    "dim2 = [] # storing second dimensions of image for analysis\n",
    "\n",
    "for image_filename in os.listdir(combined_path_train+'/normal'): # parse through all non-cancer images\n",
    "    if 'mask' not in image_filename:\n",
    "      img = mpimg.imread(combined_path_train+'/normal'+'/'+image_filename) # convert image to array\n",
    "      d1,d2,colors = img.shape # get dimensions of image\n",
    "      dim1.append(d1) # append to dimension 1 list\n",
    "      dim2.append(d2) # append to dimension 2 list\n",
    "\n",
    "for image_filename in os.listdir(combined_path_train+'/malignant'): # parse through all cancer images\n",
    "    if 'mask' not in image_filename:\n",
    "      img = mpimg.imread(combined_path_train+'/malignant'+'/'+image_filename) # convert image to array\n",
    "      d1,d2,colors = img.shape # get dimensions of image\n",
    "      dim1.append(d1) # append to dimension 1 list\n",
    "      dim2.append(d2) # append to dimension 2 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euv3dUZ93pbR"
   },
   "outputs": [],
   "source": [
    "# check for variations in dimensions\n",
    "np.mean(dim1),np.mean(dim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkXcv7Ke3pYM"
   },
   "outputs": [],
   "source": [
    "# standard shape of image\n",
    "image_shape = (226,226,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfFRLP4q6yzn"
   },
   "outputs": [],
   "source": [
    "# import library for image manipulation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbSIUfRgb_lh"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(x):\n",
    "    if 'mask' not in x:\n",
    "      return x\n",
    "    else:\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_jQsF556yzo"
   },
   "outputs": [],
   "source": [
    "# set up generator for image manipulation to add diversity in dataset\n",
    "image_gen = ImageDataGenerator(rotation_range=20, # rotate 20 degrees\n",
    "                               width_shift_range=0.10, # shift width by max of 5%\n",
    "                               height_shift_range=0.10, # shift height by max of 5%\n",
    "                               rescale=1/255, # rescale image by normalzing\n",
    "                               shear_range=0.1, # cutting part of image (max 10%)\n",
    "                               zoom_range=0.1, # zoom by 10% max\n",
    "                               horizontal_flip=True, # horizontal flip\n",
    "                               fill_mode='nearest', # fill missing pixels with nearest filled value\n",
    "                               preprocessing_function=preprocess_image # preprocess image\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbDHOvvg6yzo"
   },
   "outputs": [],
   "source": [
    "# rerun this cell as an example of how image is transformed\n",
    "plt.imshow(image_gen.random_transform(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zlai9iPOb8xl"
   },
   "source": [
    "## Convolutional Neural Network Model for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lw69S97cbxDd"
   },
   "outputs": [],
   "source": [
    "# import relevant libraries from tensor flow for model construction\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNWoi2FebdQm"
   },
   "outputs": [],
   "source": [
    "model = Sequential()  # make sequential model\n",
    "\n",
    "# add convolutional layers with pooling layers (max pooling)\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=image_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flatten output\n",
    "model.add(Flatten())\n",
    "\n",
    "# add batch normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# add layer of neurons with 'relu' activation\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# add dropout layer, rate=0.5\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# final output neuron for prediction (cancer or not cancer) with 'sigmoid' activation\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# compile model with 'ADAM' optimizer\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvBSwsXscwPV"
   },
   "outputs": [],
   "source": [
    "# prints out model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3Qr4q5YcwBY"
   },
   "outputs": [],
   "source": [
    "# early stopping to monitor validation loss for no improvement\n",
    "early_stop = EarlyStopping(monitor='loss',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbDBh9266yzr"
   },
   "outputs": [],
   "source": [
    "batch_size = 32 # to train in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osaySPx0bdQo"
   },
   "outputs": [],
   "source": [
    "# generator to get training images from combined path\n",
    "train_image_gen = image_gen.flow_from_directory(combined_path_train,\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='grayscale',\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWlR-rYZ6yzs"
   },
   "outputs": [],
   "source": [
    "train_image_gen.class_indices # check labels of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RGLWRzO6yzt"
   },
   "outputs": [],
   "source": [
    "# suppress any warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TquZ7Twf6yzt"
   },
   "outputs": [],
   "source": [
    "# fit the model on dataset\n",
    "results = model.fit(train_image_gen,epochs=20,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfTLQzSRbdQp"
   },
   "outputs": [],
   "source": [
    "# # save entire CNN model\n",
    "# model.save('cnn_balanced_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTzDg9YLbdQp"
   },
   "outputs": [],
   "source": [
    "# # save weights separately\n",
    "# model.save_weights('cnn_balanced_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9sw3agfbdQq"
   },
   "outputs": [],
   "source": [
    "# # import relevant library to store model history as json file\n",
    "# import json\n",
    "# with open('cnn_balanced_history.json', 'w') as f:\n",
    "#     json.dump(results.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnBK0DjHbdQq"
   },
   "outputs": [],
   "source": [
    "# # save model architecture to JSON\n",
    "# with open(\"cnn_balanced_architecture.json\", \"w\") as json_file:\n",
    "#     json_file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMNfLZ-xcwqZ"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb3fXqxsczND"
   },
   "outputs": [],
   "source": [
    "# store results as dataframe\n",
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFZs8YjOczIr"
   },
   "outputs": [],
   "source": [
    "# plot training and validation losses\n",
    "ax = losses[['loss']].plot()\n",
    "\n",
    "# set title and labels\n",
    "ax.set_title('Training Losses', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epochs', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t70RMNXebdQr"
   },
   "outputs": [],
   "source": [
    "# plot training and validation accuracies\n",
    "ax = losses[['accuracy']].plot()\n",
    "\n",
    "# set title and labels\n",
    "ax.set_title('Training Accuracies', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epochs', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gP65u39yczFM"
   },
   "outputs": [],
   "source": [
    "# metrics that were analyzed during fitting\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyfio8WlczCR"
   },
   "outputs": [],
   "source": [
    "# example evaluation on validation dataset to get those metrics\n",
    "model.evaluate(train_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJv5cL1Q6yzw"
   },
   "outputs": [],
   "source": [
    "# predict on validation dataset\n",
    "pred_probabilities = model.predict(train_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVr8MXXG6yzx"
   },
   "outputs": [],
   "source": [
    "# classify predictions in binary method\n",
    "predictions = pred_probabilities > 0.5\n",
    "# predictions = (pred > 0.5).astype('int') # another way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnRS0mvG6yzx"
   },
   "outputs": [],
   "source": [
    "train_image_gen.classes # check labels of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bozyPt9V6yzy"
   },
   "outputs": [],
   "source": [
    "# import relevant libraries for classification metrics and quantitative analysis\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEahhAlR6yz7"
   },
   "outputs": [],
   "source": [
    "# print classification report to understand key metrics\n",
    "print(classification_report(train_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yx7KnBF76yz8"
   },
   "outputs": [],
   "source": [
    "# print confusion matrix to investigate accurate predictions\n",
    "print(confusion_matrix(train_image_gen.classes,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z94v9AhVbdQ2"
   },
   "outputs": [],
   "source": [
    "# get confusion matrix\n",
    "cm = confusion_matrix(train_image_gen.classes,predictions)\n",
    "\n",
    "# extract True Positives, False Negatives, False Positives, True Negatives\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# calculate sensitivity and specificity\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72DVNSGdbdQ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# calculate AUC-ROC score\n",
    "auc_roc = roc_auc_score(train_image_gen.classes,predictions)\n",
    "print(f\"AUC-ROC Score: {auc_roc:.8f}\")\n",
    "\n",
    "# compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(train_image_gen.classes,predictions)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='green', lw=2, label=f'ROC curve (AUC = {auc_roc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=12)\n",
    "plt.ylabel('True Positive Rate',fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve',fontsize=14,fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-InRZTQ6yz9"
   },
   "source": [
    "## Prediction on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_GZPZHP_og4"
   },
   "outputs": [],
   "source": [
    "# import relevant library for image analysis\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOLJ_zvS6yz-"
   },
   "outputs": [],
   "source": [
    "train_imgs = [] # list to store all training image names\n",
    "\n",
    "for file in os.listdir(combined_path_train+'/normal'): # parse through training directory and get all normal cell images\n",
    "    train_imgs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YUrSDhN6yz-"
   },
   "outputs": [],
   "source": [
    "# load an example image - can change number\n",
    "my_image = image.load_img(os.path.join(combined_path_train+'/normal',train_imgs[3]),target_size=image_shape,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Axhg3AkO6yz_"
   },
   "outputs": [],
   "source": [
    "# plot to see the image of cell\n",
    "plt.imshow(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmn4zA-s6yz_"
   },
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(my_image) # convert from image file to array for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCaAr0v4bdQ4"
   },
   "outputs": [],
   "source": [
    "my_image_array = np.expand_dims(my_image, axis=0)  # Shape becomes (1, 224, 224, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AZghnEn6yz_"
   },
   "outputs": [],
   "source": [
    "my_image_array.shape # check shape of image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PrS5B1s6y0A"
   },
   "outputs": [],
   "source": [
    "model.predict(my_image_array) # make prediction on current selected cell - should be normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AADZLbvu6y0B"
   },
   "outputs": [],
   "source": [
    "train_image_gen.class_indices # definition of indices"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
